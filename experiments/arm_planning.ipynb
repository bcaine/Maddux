{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "import tf_rl\n",
    "from tf_rl.controller import DiscreteDeepQ, HumanController\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from maddux.rl_experiments.planning import Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpGi0gjH\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = tempfile.mkdtemp()\n",
    "print(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_DIR = \"/home/colin/robots/maddux/saved_experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game = Planning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow business - it is always good to reset a graph before creating a new controller.\n",
    "tf.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# This little guy will let us run tensorboard\n",
    "#      tensorboard --logdir [LOG_DIR]\n",
    "journalist = tf.train.SummaryWriter(LOG_DIR)\n",
    "\n",
    "# Brain maps from observation to Q values for different actions.\n",
    "# Here it is a done using a multi layer perceptron with 2 hidden\n",
    "# layers\n",
    "brain = MLP([game.observation_size,], [50, 50, game.num_actions], \n",
    "            [tf.tanh, tf.tanh, tf.identity])\n",
    "\n",
    "# The optimizer to use. Here we use RMSProp as recommended\n",
    "# by the publication\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate= 0.001, decay=0.9)\n",
    "\n",
    "# DiscreteDeepQ object\n",
    "current_controller = DiscreteDeepQ(game.observation_size, game.num_actions, brain, \n",
    "                                   optimizer, session, discount_rate=0.9, \n",
    "                                   exploration_period=5000, max_experience=10000, \n",
    "                                   store_every_nth=1, train_every_nth=1,\n",
    "                                   summary_writer=journalist)\n",
    "\n",
    "session.run(tf.initialize_all_variables())\n",
    "session.run(current_controller.target_network_update)\n",
    "# graph was not available when journalist was created  \n",
    "journalist.add_graph(session.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 75: iterations before success 18. Total Rewards: -0.402869510173 Last 5 rewards: [3.7001153205373782e-05, 0.19312160638971143, 0.19941359446734896, 0.20441436731287688, -1]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib\n",
    "\n",
    "iterations_needed = []\n",
    "total_rewards = []\n",
    "\n",
    "try:\n",
    "    for game_idx in range(10000):\n",
    "        game = Planning()\n",
    "        game_iterations = 0\n",
    "\n",
    "        observation = game.observe()\n",
    "        while game_iterations < 100 and not game.is_over():\n",
    "            action = current_controller.action(observation)\n",
    "            reward = game.collect_reward(action)\n",
    "            new_observation = game.observe()\n",
    "            current_controller.store(observation, action, reward, new_observation)\n",
    "            current_controller.training_step()\n",
    "            observation = new_observation\n",
    "            game_iterations += 1\n",
    "        total_rewards.append(sum(game.collected_rewards))\n",
    "        iterations_needed.append(game_iterations)\n",
    "        rewards = []\n",
    "        if game_idx % 25 == 0:\n",
    "            print \"\\rGame %d: iterations before success %d.\" % (game_idx, game_iterations),\n",
    "            print \"Total Rewards: %s\" % (sum(game.collected_rewards)),\n",
    "            print \"Last 5 rewards: {}\".format(game.collected_rewards[-5:]),\n",
    "            game.save_path(SAVE_DIR, game_idx)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print \"Interrupted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(total_rewards[0:500], label='Reward')\n",
    "plt.plot(iterations_needed[0:500], label='Iterations Needed')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.jointplot(np.array(iterations_needed), np.array(total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterations_needed[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
